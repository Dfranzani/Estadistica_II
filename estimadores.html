<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>A Estimadores | Estadística II &amp; Inferencia Estadística</title>
  <meta name="description" content="Curso básico de Estadística para ingeniería." />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="A Estimadores | Estadística II &amp; Inferencia Estadística" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Curso básico de Estadística para ingeniería." />
  <meta name="github-repo" content="Dfranzani/Estadistica_II" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A Estimadores | Estadística II &amp; Inferencia Estadística" />
  
  <meta name="twitter:description" content="Curso básico de Estadística para ingeniería." />
  

<meta name="author" content="Prof. Daniel Franzani" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regresion-lineal.html"/>
<link rel="next" href="métricas.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introducción a la Estadística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentación</a></li>
<li class="chapter" data-level="1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>1</b> Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-concepto"><i class="fa fa-check"></i><b>1.1</b> Concepto</a></li>
<li class="chapter" data-level="1.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-la-media"><i class="fa fa-check"></i><b>1.2</b> Intervalo de confianza para una media</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-la-media-varianza-conocida"><i class="fa fa-check"></i><b>1.2.1</b> Varianza poblacional conocida</a></li>
<li class="chapter" data-level="1.2.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-media-varianza-desconocida"><i class="fa fa-check"></i><b>1.2.2</b> Varianza poblacional desconocida</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-la-diferencia-de-medias"><i class="fa fa-check"></i><b>1.3</b> Intervalo de confianza para la diferencia de medias</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-la-diferencia-de-medias-varianzas-conocidas"><i class="fa fa-check"></i><b>1.3.1</b> Varianzas poblacionales conocidas</a></li>
<li class="chapter" data-level="1.3.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-la-diferencia-de-medias-varianzas-desconocidas-iguales"><i class="fa fa-check"></i><b>1.3.2</b> Varianzas poblacionales desconocidas e iguales</a></li>
<li class="chapter" data-level="1.3.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-la-diferencia-de-medias-varianzas-desconocidas-distintas"><i class="fa fa-check"></i><b>1.3.3</b> Varianzas poblacionales desconocidas y distintas</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-comparacion-de-varianzas"><i class="fa fa-check"></i><b>1.4</b> Intervalo de confianza para la comparación de varianzas</a>
<ul>
<li class="chapter" data-level="" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#distribucion-f"><i class="fa fa-check"></i>Distribución F</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#ejercicios-unidad1"><i class="fa fa-check"></i><b>1.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="PH.html"><a href="PH.html"><i class="fa fa-check"></i><b>2</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="2.1" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-concepto"><i class="fa fa-check"></i><b>2.1</b> Concepto</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-elaboracion"><i class="fa fa-check"></i><b>2.1.1</b> Elaboración</a></li>
<li class="chapter" data-level="2.1.2" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-errores"><i class="fa fa-check"></i><b>2.1.2</b> Errores tipo I y II</a></li>
<li class="chapter" data-level="2.1.3" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-procedimiento"><i class="fa fa-check"></i><b>2.1.3</b> Procedimiento de prueba</a></li>
<li class="chapter" data-level="2.1.4" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-intervalos-de-confianza"><i class="fa fa-check"></i><b>2.1.4</b> Intervalos de confianza</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="PH.html"><a href="PH.html#pruebas"><i class="fa fa-check"></i><b>2.2</b> Prueba de hipótesis para una media</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-media-varianza-conocida"><i class="fa fa-check"></i><b>2.2.1</b> Varianza poblacional conocida</a></li>
<li class="chapter" data-level="2.2.2" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-media-varianza-desconocida"><i class="fa fa-check"></i><b>2.2.2</b> Varianza poblacional desconocida</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-diferencia-de-medias"><i class="fa fa-check"></i><b>2.3</b> Prueba de hipótesis para la diferencia de medias</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-diferencia-de-medias-varianzas-conocidas"><i class="fa fa-check"></i><b>2.3.1</b> Varianzas poblacionales conocidas</a></li>
<li class="chapter" data-level="2.3.2" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-diferencia-de-medias-varianzas-desconocidas-iguales"><i class="fa fa-check"></i><b>2.3.2</b> Varianzas poblacionales desconocidas e iguales</a></li>
<li class="chapter" data-level="2.3.3" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-diferencia-de-medias-varianzas-desconocidas-distintas"><i class="fa fa-check"></i><b>2.3.3</b> Varianzas poblacionales desconocidas y distintas</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-comparacion-varianzas"><i class="fa fa-check"></i><b>2.4</b> Prueba de hipótesis para comparación de varianzas</a></li>
<li class="chapter" data-level="2.5" data-path="PH.html"><a href="PH.html#prueba-de-hipotesis-diferencia-proporciones"><i class="fa fa-check"></i><b>2.5</b> Prueba de hipótesis para la diferencia de proporciones</a></li>
<li class="chapter" data-level="2.6" data-path="PH.html"><a href="PH.html#ejercicios-unidad2"><i class="fa fa-check"></i><b>2.6</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regresion-lineal.html"><a href="regresion-lineal.html"><i class="fa fa-check"></i><b>3</b> Regresión Lineal</a>
<ul>
<li class="chapter" data-level="3.1" data-path="regresion-lineal.html"><a href="regresion-lineal.html#regresion-lineal-medidas-asociacion"><i class="fa fa-check"></i><b>3.1</b> Medidas de asociación lineal</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="regresion-lineal.html"><a href="regresion-lineal.html#regresion-lineal-covarianza"><i class="fa fa-check"></i><b>3.1.1</b> Covarianza</a></li>
<li class="chapter" data-level="3.1.2" data-path="regresion-lineal.html"><a href="regresion-lineal.html#regresion-lineal-correlacion"><i class="fa fa-check"></i><b>3.1.2</b> Correlación</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="regresion-lineal.html"><a href="regresion-lineal.html#regresion-lineal-simple"><i class="fa fa-check"></i><b>3.2</b> Regresión lineal simple</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="regresion-lineal.html"><a href="regresion-lineal.html#EMCRLS"><i class="fa fa-check"></i><b>3.2.1</b> Estimadores de mínimos cuadrados</a></li>
<li class="chapter" data-level="3.2.2" data-path="regresion-lineal.html"><a href="regresion-lineal.html#sumascuadraticas"><i class="fa fa-check"></i><b>3.2.2</b> Sumas cuadráticas</a></li>
<li class="chapter" data-level="3.2.3" data-path="regresion-lineal.html"><a href="regresion-lineal.html#pruebasHipotesisRLS"><i class="fa fa-check"></i><b>3.2.3</b> Pruebas de hipótesis</a></li>
<li class="chapter" data-level="3.2.4" data-path="regresion-lineal.html"><a href="regresion-lineal.html#metricasRLS"><i class="fa fa-check"></i><b>3.2.4</b> Métricas</a></li>
<li class="chapter" data-level="3.2.5" data-path="regresion-lineal.html"><a href="regresion-lineal.html#regresion-lineal-simple-supuestos"><i class="fa fa-check"></i><b>3.2.5</b> Supuestos</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="regresion-lineal.html"><a href="regresion-lineal.html#regresion-lineal-multiple"><i class="fa fa-check"></i><b>3.3</b> Regresión lineal múltiple</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="regresion-lineal.html"><a href="regresion-lineal.html#EMC-RLM-CUERPO"><i class="fa fa-check"></i><b>3.3.1</b> Estimadores de mínimos cuadrados</a></li>
<li class="chapter" data-level="3.3.2" data-path="regresion-lineal.html"><a href="regresion-lineal.html#covariables-cualitativas"><i class="fa fa-check"></i><b>3.3.2</b> Covariables cualitativas</a></li>
<li class="chapter" data-level="3.3.3" data-path="regresion-lineal.html"><a href="regresion-lineal.html#regresion-lineal-multiple-pruebas-hipotesis"><i class="fa fa-check"></i><b>3.3.3</b> Pruebas de hipótesis</a></li>
<li class="chapter" data-level="3.3.4" data-path="regresion-lineal.html"><a href="regresion-lineal.html#metricasRLM"><i class="fa fa-check"></i><b>3.3.4</b> Métricas</a></li>
<li class="chapter" data-level="3.3.5" data-path="regresion-lineal.html"><a href="regresion-lineal.html#regresion-lineal-multiple-supuestos"><i class="fa fa-check"></i><b>3.3.5</b> Supuestos</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="regresion-lineal.html"><a href="regresion-lineal.html#regresion-lineal-seleccion-variables"><i class="fa fa-check"></i><b>3.4</b> Selección de variables</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="regresion-lineal.html"><a href="regresion-lineal.html#regresion-lineal-seleccion-variables-forward"><i class="fa fa-check"></i><b>3.4.1</b> Forward</a></li>
<li class="chapter" data-level="3.4.2" data-path="regresion-lineal.html"><a href="regresion-lineal.html#regresion-lineal-seleccion-variables-backward"><i class="fa fa-check"></i><b>3.4.2</b> Backward</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="regresion-lineal.html"><a href="regresion-lineal.html#regresion-lineal-prediccion-observaciones"><i class="fa fa-check"></i><b>3.5</b> Predicción de observaciones</a></li>
<li class="chapter" data-level="3.6" data-path="regresion-lineal.html"><a href="regresion-lineal.html#ejercicios-unidad-3"><i class="fa fa-check"></i><b>3.6</b> Ejercicios</a></li>
</ul></li>
<li class="appendix"><span><b>Apéndice</b></span></li>
<li class="chapter" data-level="A" data-path="estimadores.html"><a href="estimadores.html"><i class="fa fa-check"></i><b>A</b> Estimadores</a>
<ul>
<li class="chapter" data-level="A.1" data-path="estimadores.html"><a href="estimadores.html#RLS-EMC"><i class="fa fa-check"></i><b>A.1</b> EMC en Regresión Lineal Simple</a></li>
<li class="chapter" data-level="A.2" data-path="04-Anexos.html"><a href="#descomposici%C3%B3n-de-la-suma-de-cuadrados-total"><i class="fa fa-check"></i><b>A.2</b> Descomposición de la Suma de Cuadrados Total</a></li>
<li class="chapter" data-level="A.3" data-path="estimadores.html"><a href="estimadores.html#RLM-EMC"><i class="fa fa-check"></i><b>A.3</b> EMC en Regresión Lineal Múltiple</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="04-Anexos.html"><a href="#m%C3%A9tricas"><i class="fa fa-check"></i><b>B</b> Métricas</a>
<ul>
<li class="chapter" data-level="B.1" data-path="métricas.html"><a href="métricas.html"><i class="fa fa-check"></i><b>B.1</b> <span class="math inline">\(R^2\)</span> y <span class="math inline">\(R^2\)</span> ajustado</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="04-Anexos.html"><a href="#estad%C3%ADsticos"><i class="fa fa-check"></i><b>C</b> Estadísticos</a>
<ul>
<li class="chapter" data-level="C.1" data-path="estadísticos.html"><a href="estadísticos.html"><i class="fa fa-check"></i><b>C.1</b> Estadístico F del método de selección Forward</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="funciones.html"><a href="funciones.html"><i class="fa fa-check"></i><b>D</b> Funciones</a>
<ul>
<li class="chapter" data-level="D.1" data-path="funciones.html"><a href="funciones.html#funcion-indicatriz"><i class="fa fa-check"></i><b>D.1</b> Esquema de la función indicatriz</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/rmarkdown-cookbook" target="blank">Published with Bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística II &amp; Inferencia Estadística</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimadores" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">A</span> Estimadores<a href="estimadores.html#estimadores" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="RLS-EMC" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">A.1</span> EMC en Regresión Lineal Simple<a href="estimadores.html#RLS-EMC" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El proceso de obtención de los estimadores de mínimos cuadrado en una regresión lineal simple es el siguiente:</p>
<span class="math display" id="eq:betasestimador-demostracion">\[\begin{equation}
\begin{split}
S(\beta_0,\beta_1) &amp;= \sum_{i=1}^n\varepsilon_i^2 = \sum_{i=1}^n (Y_i - [\beta_0 + \beta_1X_i])^2
\end{split}
\tag{A.1}
\end{equation}\]</span>
<p>Para determinar el estimador de <span class="math inline">\(\beta_0\)</span> se calcula la derivada parcial la función <span class="math inline">\(S(\cdot)\)</span> respecto a este parámetro.</p>
<span class="math display" id="eq:beta0estimador-demostracion1">\[\begin{equation}
\begin{split}
\frac{\partial S}{\partial\beta_0} &amp;= \frac{\partial }{\partial\beta_0}\left(\sum_{i=1}^n (Y_i - [\beta_0 + \beta_1X_i])^2\right)\\
&amp;= \sum_{i=1}^n 2(Y_i - [\beta_0 + \beta_1X_i])(-1)\\
&amp;= -2\sum_{i=1}^n (Y_i - [\beta_0 + \beta_1X_i])\\
\end{split}
\tag{A.2}
\end{equation}\]</span>
<p>Igualando a cero y despejando el parámetro, el estimador es:</p>
<span class="math display" id="eq:beta0estimador-demostracion2">\[\begin{equation}
\begin{split}
&amp;-2\sum_{i=1}^n (Y_i - [\beta_0 + \beta_1X_i]) = 0\\
&amp;\sum_{i=1}^n (Y_i - \beta_0 - \beta_1X_i) = 0\\
&amp;\sum_{i=1}^n Y_i - n\beta_0 - \beta_1\sum_{i=1}^nX_i = 0\\
&amp;\sum_{i=1}^n Y_i - \beta_1\sum_{i=1}^nX_i = n\beta_0\\
&amp;\widehat{\beta}_0 = \bar{Y} - \beta_1\bar{X} \\
\end{split}
\tag{A.3}
\end{equation}\]</span>
<p>Para determinar el estimador de <span class="math inline">\(\beta_1\)</span> se calcula la derivada parcial la función <span class="math inline">\(S(\cdot)\)</span> respecto a este parámetro.</p>
<span class="math display" id="eq:beta1estimador-demostracion1">\[\begin{equation}
\begin{split}
\frac{\partial S}{\partial\beta_1} &amp;= \frac{\partial }{\partial\beta_1}\left(\sum_{i=1}^n (Y_i - [\beta_0 + \beta_1X_i])^2\right)\\
&amp;= \sum_{i=1}^n 2(Y_i - [\beta_0 + \beta_1X_i])(-X_i)\\
&amp;= -2\sum_{i=1}^n (Y_i - [\beta_0 + \beta_1X_i])X_i\\
\end{split}
\tag{A.4}
\end{equation}\]</span>
<p>Igualando a cero.</p>
<span class="math display" id="eq:beta1estimador-demostracion2">\[\begin{equation}
\begin{split}
-2\sum_{i=1}^n (Y_i - [\beta_0 + \beta_1X_i])X_i &amp;= 0\\
\sum_{i=1}^n (Y_iX_i - \beta_0X_i - \beta_1X_i^2) &amp;= 0\\
\end{split}
\tag{A.5}
\end{equation}\]</span>
<p>Reemplazamos el estimador obtenido en <a href="estimadores.html#eq:beta0estimador-demostracion2">(A.3)</a>.</p>
<span class="math display" id="eq:beta1estimador-demostracion3">\[\begin{equation}
\begin{split}
\sum_{i=1}^n (Y_iX_i - (\bar{Y} - \beta_1\bar{X})X_i - \beta_1X_i^2) &amp;= 0\\
\sum_{i=1}^n (Y_iX_i - \bar{Y}X_i + \beta_1\bar{X}X_i - \beta_1X_i^2) &amp;= 0\\
\sum_{i=1}^n (Y_iX_i - \bar{Y}X_i) + \beta_1\sum_{i=1}^n(\bar{X}X_i - X_i^2) &amp;= 0\\
\end{split}
\tag{A.6}
\end{equation}\]</span>
<p>Cada una de las sumatorias se puede reescribir de la siguiente manera:</p>
<span class="math display" id="eq:beta1estimador-demostracion4">\[\begin{equation}
\begin{split}
\sum_{i=1}^n(\bar{X}X_i - X_i^2) &amp;= \sum_{i=1}^n(\bar{X}X_i - X_i^2 + \bar{X}^2 + \bar{X}X_i - \bar{X}^2 - \bar{X}X_i)\\
&amp;= \sum_{i=1}^n(\bar{X}X_i - X_i^2 + \bar{X}^2 + \bar{X}X_i - \bar{X}^2 - \bar{X}X_i)\\
&amp;= -\sum_{i=1}^n(X_i -\bar{X})^2 + \sum_{i=1}^n\bar{X}(\bar{X}-X_i)\\
&amp;= -\sum_{i=1}^n(X_i -\bar{X})^2 + 0\\
&amp;= -\sum_{i=1}^n(X_i -\bar{X})^2\\
\end{split}
\tag{A.7}
\end{equation}\]</span>
<span class="math display" id="eq:beta1estimador-demostracion5">\[\begin{equation}
\begin{split}
\sum_{i=1}^n (Y_iX_i - \bar{Y}X_i) &amp;= \sum_{i=1}^n (Y_iX_i - \bar{Y}X_i + Y_i\bar{X} + \bar{Y}\bar{X} - Y_i\bar{X} - \bar{Y}\bar{X})\\
&amp;= \sum_{i=1}^n (Y_i(X_i - \bar{X}) - \bar{Y}(X_i - \bar{X})) + \sum_{i=1}^n(Y_i\bar{X} - \bar{Y}\bar{X}) \\
&amp;= \sum_{i=1}^n (Y_i - \bar{Y})(X_i - \bar{X}) + 0 \\
&amp;= \sum_{i=1}^n (Y_i - \bar{Y})(X_i - \bar{X})\\
\end{split}
\tag{A.8}
\end{equation}\]</span>
<p>Reemplazando <a href="estimadores.html#eq:beta1estimador-demostracion4">(A.7)</a> y <a href="estimadores.html#eq:beta1estimador-demostracion5">(A.8)</a> en la ecuación <a href="estimadores.html#eq:beta1estimador-demostracion3">(A.6)</a>, el estimador de <span class="math inline">\(\beta_1\)</span> es:</p>
<span class="math display" id="eq:beta1estimador-demostracion6">\[\begin{equation}
\begin{split}
&amp;\sum_{i=1}^n (Y_iX_i - \bar{Y}X_i) + \beta_1\sum_{i=1}^n(\bar{X}X_i - X_i^2) = 0 \\
&amp;\sum_{i=1}^n (Y_i - \bar{Y})(X_i - \bar{X}) - \beta_1\sum_{i=1}^n(X_i -\bar{X})^2 = 0 \\
&amp;\beta_1\sum_{i=1}^n(X_i -\bar{X})^2 = \sum_{i=1}^n (Y_i - \bar{Y})(X_i - \bar{X}) \\
&amp;\widehat{\beta}_1 = \frac{\displaystyle\sum_{i=1}^n (Y_i - \bar{Y})(X_i - \bar{X})}{\displaystyle\sum_{i=1}^n(X_i -\bar{X})^2} \\
\end{split}
\tag{A.9}
\end{equation}\]</span>
<p>Luego, se puede reescribir el estimador de <span class="math inline">\(\beta_0\)</span> de la siguiente manera:</p>
<span class="math display" id="eq:beta0estimador-demostracion3">\[\begin{equation}
\begin{split}
&amp;\widehat{\beta}_0 = \bar{Y} - \widehat{\beta}_1\bar{X} \\
\end{split}
\tag{A.10}
\end{equation}\]</span>
</div>
<div id="descomposición-de-la-suma-de-cuadrados-total" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">A.2</span> Descomposición de la Suma de Cuadrados Total<a href="#descomposici%C3%B3n-de-la-suma-de-cuadrados-total" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En la sección <a href="regresion-lineal.html#sumascuadraticas">3.2.2</a>, la ecuación <a href="regresion-lineal.html#eq:descomposicion-sct">(3.11)</a> plantea que la suma de cuadrados total (SCT) se puede descomponer en la suma de cuadrados del modelo (SCReg) y la suma de cuadrados del error (SCE). La demostración es la siguiente:</p>
<span class="math display" id="eq:demostracionSCT1">\[\begin{equation}
\begin{split}
\sum_{i=1}^n\left( Y_i - \bar{Y} \right)^2 &amp;= \sum_{i=1}^n\left( \left( \widehat{Y}_i - \bar{Y} \right) + \left( Y_i - \widehat{Y}_i \right) \right)^2\\
&amp;= \sum_{i=1}^n\left( \widehat{Y}_i - \bar{Y} \right)^2  + 2\sum_{i=1}^n\left( \widehat{Y}_i - \bar{Y} \right)\left( Y_i - \widehat{Y}_i \right) + \sum_{i=1}^n\left( Y_i - \widehat{Y}_i \right)^2\\
\end{split}
\tag{A.11}
\end{equation}\]</span>
<p>Luego, basta demostrar que</p>
<span class="math display" id="eq:demostracionSCT2">\[\begin{equation}
\begin{split}
\sum_{i=1}^n\left( \widehat{Y}_i - \bar{Y} \right)\left( Y_i - \widehat{Y}_i \right) = 0
\end{split}
\tag{A.12}
\end{equation}\]</span>
<p>Partiendo desde el lado izquierda de la igualdad, se tiene que</p>
<span class="math display" id="eq:demostracionSCT3">\[\begin{equation}
\begin{split}
\sum_{i=1}^n\left( \widehat{Y}_i - \bar{Y} \right)\left( Y_i - \widehat{Y}_i \right) &amp;= \sum_{i=1}^n\left( \widehat{\beta}_0 + \widehat{\beta}_1X_i - \bar{Y} \right)\left( Y_i - \left( \widehat{\beta}_0 + \widehat{\beta}_1X_i \right) \right)\\
\end{split}
\tag{A.13}
\end{equation}\]</span>
<p>Reemplazando el estimador de mínimos cuadrados de <span class="math inline">\(\beta_0\)</span> obtenido en <a href="estimadores.html#eq:beta0estimador-demostracion3">(A.10)</a>, se tiene que lo anterior es igual a</p>
<span class="math display" id="eq:demostracionSCT4">\[\begin{equation}
\begin{split}
&amp;= \sum_{i=1}^n\left( \bar{Y} - \widehat{\beta}_1\bar{X} + \widehat{\beta}_1X_i - \bar{Y} \right)\left( Y_i - \bar{Y} + \widehat{\beta}_1\bar{X} - \widehat{\beta}_1X_i \right)\\
&amp;= \widehat{\beta}_1\sum_{i=1}^n\left(-\bar{X}  + X_i \right) \left( Y_i - \bar{Y} + \widehat{\beta}_1\bar{X} - \widehat{\beta}_1X_i \right) \\
&amp;= \widehat{\beta}_1\sum_{i=1}^n\left(X_i -\bar{X} \right) \left( Y_i - \bar{Y}\right) + \widehat{\beta}_1\sum_{i=1}^n\left(X_i -\bar{X} \right)\widehat{\beta}_1 \left( \bar{X} - X_i \right) \\
&amp;= \widehat{\beta}_1\sum_{i=1}^n\left(X_i -\bar{X} \right) \left( Y_i - \bar{Y}\right) - \widehat{\beta}_1^2\sum_{i=1}^n\left(X_i -\bar{X} \right)^2 \\
\end{split}
\tag{A.14}
\end{equation}\]</span>
<p>Reemplazando el estimador de mínimos cuadrados de <span class="math inline">\(\beta_1\)</span> obtenido en <a href="estimadores.html#eq:beta1estimador-demostracion6">(A.9)</a>, se tiene que lo anterior es igual a</p>
<span class="math display" id="eq:demostracionSCT5">\[\begin{equation}
\begin{split}
&amp;= \frac{\displaystyle\sum_{i=1}^n (Y_i - \bar{Y})(X_i - \bar{X})}{\displaystyle\sum_{i=1}^n(X_i -\bar{X})^2}\sum_{i=1}^n\left(X_i -\bar{X} \right) \left( Y_i - \bar{Y}\right)\\
&amp; \hspace{2cm} - \left( \frac{\displaystyle\sum_{i=1}^n (Y_i - \bar{Y})(X_i - \bar{X})}{\displaystyle\sum_{i=1}^n(X_i -\bar{X})^2} \right)^2\sum_{i=1}^n\left(X_i -\bar{X} \right)^2 \\
&amp;= \frac{\left(\displaystyle\sum_{i=1}^n (Y_i - \bar{Y})(X_i - \bar{X})\right)^2}{\displaystyle\sum_{i=1}^n(X_i -\bar{X})^2} - \frac{\left( \displaystyle\sum_{i=1}^n (Y_i - \bar{Y})(X_i - \bar{X})\right)^2}{\left(\displaystyle\sum_{i=1}^n(X_i -\bar{X})^2\right)^2} \sum_{i=1}^n\left(X_i -\bar{X} \right)^2 \\
&amp;= \frac{\left(\displaystyle\sum_{i=1}^n (Y_i - \bar{Y})(X_i - \bar{X})\right)^2}{\displaystyle\sum_{i=1}^n(X_i -\bar{X})^2} - \frac{\left( \displaystyle\sum_{i=1}^n (Y_i - \bar{Y})(X_i - \bar{X})\right)^2}{\displaystyle\sum_{i=1}^n(X_i -\bar{X})^2}\\
&amp; = 0
\end{split}
\tag{A.15}
\end{equation}\]</span>
<p>Quedando así demostrada la descomposición de las Suma de Cuadrados Total.</p>
</div>
<div id="RLM-EMC" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">A.3</span> EMC en Regresión Lineal Múltiple<a href="estimadores.html#RLM-EMC" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El proceso de obtención de los estimadores de mínimos cuadrado en una regresión lineal múltiple corresponde a la minimización de la suma cuadrática de los errores.</p>
<span class="math display" id="eq:betasmultiple-demostracion">\[\begin{equation}
\begin{split}
S(\beta) = \varepsilon^t\varepsilon &amp;= (Y - X\beta)^t(Y - X\beta)\\
&amp;= (Y^t - \beta^tX^t)(Y - X\beta)\\
&amp;= Y^tY - Y^tX\beta - \beta^tX^tY + \beta^tX^tX\beta\\
\end{split}
\tag{A.16}
\end{equation}\]</span>
<p>Luego, derivando respecto a <span class="math inline">\(\beta\)</span>.</p>
<span class="math display" id="eq:betasmultiple2-demostracion">\[\begin{equation}
\begin{split}
\frac{\partial S}{\partial \beta} &amp;= - X^tY - X^tY + 2X^tX\beta\\
&amp;= - 2X^tY + 2X^tX\beta\\
\end{split}
\tag{A.17}
\end{equation}\]</span>
<p>Igualando a cero y despejando la matriz <span class="math inline">\(\beta\)</span>.</p>
<span class="math display" id="eq:betasmultiple3-demostracion">\[\begin{equation}
\begin{split}
- 2X^tY + 2X^tX\beta &amp;= 0\\
2X^tX\beta &amp;= 2X^tY\\
X^tX\beta &amp;= X^tY\\
\widehat{\beta} &amp;= (X^tX)^{-1}X^tY\\
\end{split}
\tag{A.18}
\end{equation}\]</span>
<p>El resultado de la ecuación <a href="estimadores.html#eq:betasmultiple3-demostracion">(A.18)</a> permite obtener de manera conjunta los EMC de los parámetros de un modelo de regresión lineal múltiple. Sin embargo, es posible obtener un expresión para obtener el estimador de uno de los parámetros o un subconjunto estricto de ellos.</p>
<p>Considerando el modelo de regresión lineal múltiple clásico</p>
<span class="math display" id="eq:RLM-clasico">\[\begin{equation}
\begin{split}
Y &amp;= X\beta + \varepsilon\\
\end{split}
\tag{A.19}
\end{equation}\]</span>
<p>Es posible desglosar el modelo de la siguiente forma</p>
<span class="math display" id="eq:RLM-clasico2">\[\begin{equation}
\begin{split}
Y &amp;= X_0\beta_0 + X_1\beta_1 + \varepsilon,\\
\end{split}
\tag{A.20}
\end{equation}\]</span>
<p>en el cual, <span class="math inline">\(X_0\)</span> y <span class="math inline">\(X_1\)</span> son subconjutos de columnas de la matriz de diseño <span class="math inline">\(X\)</span>, tal que, <span class="math inline">\(X = [X_1,X_2]\)</span>. Del mismo modo, <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span> son subconjutos de la matriz de parámetros <span class="math inline">\(\beta\)</span>, tal que, <span class="math inline">\(\beta = [\beta_1^t,\beta_2^t]^t\)</span>. El objetivo es obtener una expresión para el estimador de <span class="math inline">\(\beta_0\)</span>. Para ello, se minimiza la suma cuadrática de los errores del modelo.</p>
<span class="math display" id="eq:RLM-clasico3">\[\begin{equation}
\min\lbrace S(\beta_1, \beta_2) = (Y - X_0\beta_0 + X_1\beta_1)^t(Y - X_0\beta_0 + X_1\beta_1)  \rbrace
\tag{A.21}
\end{equation}\]</span>
<p>Derivando respecto a <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>, e igualando a cero.</p>
<span class="math display" id="eq:RLM-clasico4">\[\begin{equation}
\begin{split}
\frac{\partial S}{\partial \beta_0} &amp;= -2X^t_0(Y-X_0\beta_0-X_1\beta_1) = 0\\
\frac{\partial S}{\partial \beta_1} &amp;= -2X^t_1(Y-X_0\beta_0-X_1\beta_1) = 0\\
\end{split}
\tag{A.22}
\end{equation}\]</span>
<p>Despejando <span class="math inline">\(\beta_1\)</span> de la derivada respecto a <span class="math inline">\(\beta_1\)</span>.</p>
<span class="math display" id="eq:RLM-clasico5">\[\begin{equation}
\begin{split}
\beta_1 &amp;= -(X_1^tX_1)^{-1}X_1^t(Y-X_0\beta_0)\\
\end{split}
\tag{A.23}
\end{equation}\]</span>
<p>Reemplazando el resultado en la derivada respecto a <span class="math inline">\(\beta_0\)</span>.</p>
<span class="math display" id="eq:RLM-clasico6">\[\begin{equation}
\begin{split}
-2X^t_0(Y-X_0\beta_0-X_1\beta_1) &amp;= 0\\
X^t_0(Y-X_0\beta_0+X_1(X_1^tX_1)^{-1}X_1^t(Y-X_0\beta_0)) &amp;= 0\\
X^t_0Y-X^t_0X_0\beta_0+X^t_0X_1(X_1^tX_1)^{-1}X_1^t(Y-X_0\beta_0) &amp;= 0
\end{split}
\tag{A.24}
\end{equation}\]</span>
<p>Denotando <span class="math inline">\(H_1 = X_1(X_1^tX_1)^{-1}X_1^t\)</span>.</p>
<span class="math display" id="eq:RLM-clasico7">\[\begin{equation}
\begin{split}
X^t_0Y-X^t_0X_0\beta_0+X^t_0X_1(X_1^tX_1)X_1^t(Y-X_1\beta_1)) &amp;= 0\\
X^t_0Y-X^t_0X_0\beta_0+X^t_0H_1Y-X^t_0H_1X_0\beta_0 &amp;= 0\\
\end{split}
\tag{A.25}
\end{equation}\]</span>
<p>Despejando <span class="math inline">\(\beta_0\)</span></p>
<span class="math display" id="eq:RLM-clasico8">\[\begin{equation}
\begin{split}
(-X^t_0X_0-X^t_0H_1X_0)\beta_0 &amp;= -X^t_0Y - X^t_0H_1Y\\
\beta_0 &amp;= (X^t_0X_0 + X^t_0H_1X_0)^{-1}(X^t_0Y + X^t_0H_1Y)\\
\widehat{\beta}_0 &amp;= (X^t_0(I-H_1)X_0)^{-1}X^t_0(I-H_1)Y\\
\end{split}
\tag{A.26}
\end{equation}\]</span>
<p>El resultado obtenido en <a href="estimadores.html#eq:RLM-clasico8">(A.26)</a> permite obtener el estimador de un subconjunto estricto de parámetros del modelo. En particular, se obtiene a partir de la matriz de diseño <span class="math inline">\(X_0\)</span> y la matriz de proyección <span class="math inline">\(H_1\)</span> asociada a la matriz de diseño <span class="math inline">\(X_1\)</span>.</p>
<p>A continuación, se muestra una ejemplo de cómo utilizar esta expresión en R, utilizado la base de datos <code>iris</code>.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="estimadores.html#cb185-1" tabindex="-1"></a><span class="co"># Carga de la base de datos iris</span></span>
<span id="cb185-2"><a href="estimadores.html#cb185-2" tabindex="-1"></a>datos <span class="ot">=</span> iris</span>
<span id="cb185-3"><a href="estimadores.html#cb185-3" tabindex="-1"></a><span class="co"># Variables de la base de de datos</span></span>
<span id="cb185-4"><a href="estimadores.html#cb185-4" tabindex="-1"></a><span class="fu">str</span>(datos)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    150 obs. of  5 variables:
##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
##  $ Species     : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>Para el modelo de regresión lineal múltiple para estudiar el largo del sépalo a partir del resto de variables numéricas, mediante la ecuación <a href="estimadores.html#eq:RLM-clasico8">(A.26)</a> es posible obtener el estimador del parámetro asociado a las variables <em>Sepal.Width</em> y <em>Petal.Length</em>, es decir, el estimador de <span class="math inline">\(\beta_0\)</span> considerando <span class="math inline">\(X_0 = [\texttt{Sepal.Width}, \texttt{Petal.Length}]\)</span> y <span class="math inline">\(X_1 = [1, \texttt{Petal.Width}]\)</span>. Las matrices de diseño son las siguientes.</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="estimadores.html#cb187-1" tabindex="-1"></a><span class="co"># Matrices de diseño</span></span>
<span id="cb187-2"><a href="estimadores.html#cb187-2" tabindex="-1"></a>X0 <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(datos<span class="sc">$</span>Sepal.Width, datos<span class="sc">$</span>Petal.Length), <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb187-3"><a href="estimadores.html#cb187-3" tabindex="-1"></a>X1 <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">nrow</span>(datos)), datos<span class="sc">$</span>Petal.Width), <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb187-4"><a href="estimadores.html#cb187-4" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">matrix</span>(datos<span class="sc">$</span>Sepal.Length, <span class="at">ncol =</span> <span class="dv">1</span>)</span>
<span id="cb187-5"><a href="estimadores.html#cb187-5" tabindex="-1"></a>H1 <span class="ot">=</span> <span class="fu">diag</span>(<span class="fu">nrow</span>(X1)) <span class="sc">-</span> X1 <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">t</span>(X1) <span class="sc">%*%</span> X1) <span class="sc">%*%</span> <span class="fu">t</span>(X1)</span>
<span id="cb187-6"><a href="estimadores.html#cb187-6" tabindex="-1"></a>b0 <span class="ot">=</span> <span class="fu">solve</span>(<span class="fu">t</span>(X0) <span class="sc">%*%</span> H1 <span class="sc">%*%</span> X0) <span class="sc">%*%</span>  <span class="fu">t</span>(X0) <span class="sc">%*%</span> H1 <span class="sc">%*%</span> y</span>
<span id="cb187-7"><a href="estimadores.html#cb187-7" tabindex="-1"></a>b0</span></code></pre></div>
<pre><code>##           [,1]
## [1,] 0.6508372
## [2,] 0.7091320</code></pre>
<p>Se verifica el resultado anterior, ajustando un modelo de regresión lineal múltiple con la función <code>lm()</code> de R.</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="estimadores.html#cb189-1" tabindex="-1"></a><span class="co"># Modelo de regresión lineal múltiple para estudiar el largo del sépalo</span></span>
<span id="cb189-2"><a href="estimadores.html#cb189-2" tabindex="-1"></a><span class="co"># a partir del resto de variables numéricas.</span></span>
<span id="cb189-3"><a href="estimadores.html#cb189-3" tabindex="-1"></a>modelo <span class="ot">=</span> <span class="fu">lm</span>(Sepal.Length <span class="sc">~</span> Sepal.Width <span class="sc">+</span> Petal.Length <span class="sc">+</span> Petal.Width, <span class="at">data =</span> datos)</span>
<span id="cb189-4"><a href="estimadores.html#cb189-4" tabindex="-1"></a><span class="co"># Coeficientes del modelo</span></span>
<span id="cb189-5"><a href="estimadores.html#cb189-5" tabindex="-1"></a>modelo<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##  (Intercept)  Sepal.Width Petal.Length  Petal.Width 
##    1.8559975    0.6508372    0.7091320   -0.5564827</code></pre>
<p>En particular, si se desea estimar el solo uno de los parámetros del modelo, la ecuación <a href="estimadores.html#eq:RLM-clasico8">(A.26)</a> puede ser expresada de la siguiente forma.</p>
<span class="math display" id="eq:RLM-clasico9">\[\begin{equation}
\begin{split}
\widehat{\beta}_0 &amp;= \frac{X^t_0(I-H_1)Y}{X^t_0(I-H_1)X_0}\\
\end{split}
\tag{A.27}
\end{equation}\]</span>
<p>Un ejemplo de cómo utilizar esta expresión en R, estimando únicamente el parámetro asociado a <span class="math inline">\(\texttt{Sepal.Width}\)</span>.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="estimadores.html#cb191-1" tabindex="-1"></a><span class="co"># Matrices de diseño</span></span>
<span id="cb191-2"><a href="estimadores.html#cb191-2" tabindex="-1"></a>X0 <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(datos<span class="sc">$</span>Sepal.Width), <span class="at">ncol =</span> <span class="dv">1</span>)</span>
<span id="cb191-3"><a href="estimadores.html#cb191-3" tabindex="-1"></a>X1 <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">nrow</span>(datos)), datos<span class="sc">$</span>Petal.Width, datos<span class="sc">$</span>Petal.Length), <span class="at">ncol =</span> <span class="dv">3</span>)</span>
<span id="cb191-4"><a href="estimadores.html#cb191-4" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">matrix</span>(datos<span class="sc">$</span>Sepal.Length, <span class="at">ncol =</span> <span class="dv">1</span>)</span>
<span id="cb191-5"><a href="estimadores.html#cb191-5" tabindex="-1"></a>H1 <span class="ot">=</span> <span class="fu">diag</span>(<span class="fu">nrow</span>(X1)) <span class="sc">-</span> X1 <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">t</span>(X1) <span class="sc">%*%</span> X1) <span class="sc">%*%</span> <span class="fu">t</span>(X1)</span>
<span id="cb191-6"><a href="estimadores.html#cb191-6" tabindex="-1"></a>b0 <span class="ot">=</span> <span class="fu">t</span>(X0) <span class="sc">%*%</span> H1 <span class="sc">%*%</span> y<span class="sc">/</span>(<span class="fu">t</span>(X0) <span class="sc">%*%</span> H1 <span class="sc">%*%</span> X0)</span>
<span id="cb191-7"><a href="estimadores.html#cb191-7" tabindex="-1"></a>b0</span></code></pre></div>
<pre><code>##           [,1]
## [1,] 0.6508372</code></pre>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regresion-lineal.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="métricas.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": false,
    "twitter": true,
    "linkedin": true,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": true,
    "all": false
  },
  "fontsettings": false,
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["est2+inferencia.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": null
  },
  "info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
